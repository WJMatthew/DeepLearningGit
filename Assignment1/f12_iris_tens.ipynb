{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import torch.nn.functional as F\n",
    "from tensorboardX import SummaryWriter\n",
    "import my_classes as mc\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import my_classes as mc\n",
    "\n",
    "iris_data = load_iris()\n",
    "features, pre_labels = iris_data.data, iris_data.target\n",
    "\n",
    "root = './iris'\n",
    "\n",
    "if not os.path.exists(root):\n",
    "    os.mkdir(root)\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "labels = mc.one_hot_encode(pre_labels)\n",
    "\n",
    "feature_train, feature_test, labels_train, labels_test = train_test_split(features, labels, random_state = 17)\n",
    "\n",
    "# Load the standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Compute the mean and standard deviation based on the training data\n",
    "sc.fit(feature_train)\n",
    "\n",
    "# Scale the training data to be of mean 0 and of unit variance\n",
    "feature_train = sc.transform(feature_train)\n",
    "\n",
    "# Scale the test data to be of mean 0 and of unit variance\n",
    "feature_test = sc.transform(feature_test)\n",
    "\n",
    "# Data type for tensors\n",
    "dtype = torch.float\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_ent(y_hat, y):\n",
    "    soft = softmax(y_hat)\n",
    "    #print('soft',soft.shape)\n",
    "    #print('y',y.shape)\n",
    "    return torch.mean( -torch.sum(y.float() * torch.log(soft), 1))\n",
    "\n",
    "# SOFTMAX\n",
    "def softmax(X):\n",
    "    '''\n",
    "    X: output of last fc layer, dim = [num_examples, num_classes]\n",
    "    output: \n",
    "    '''\n",
    "    exps = torch.exp(X - torch.max(X))\n",
    "    return exps / exps.sum()\n",
    "\n",
    "def delta_cross_ent(X, y):\n",
    "    '''\n",
    "    X: output of last fully connected layer, dim = [num_examples, num_classes]\n",
    "    y: labels (not one-hot encoded), dim = [num_examples, 1]\n",
    "    output: gradient of cross entropy function wrt output, dim = [num_examples, num_classes]\n",
    "    '''\n",
    "    m = y.shape[1]\n",
    "    grad = softmax(X)\n",
    "    \n",
    "    #print(grad.shape)\n",
    "    #print(y.shape)\n",
    "    debug['grad'] = grad\n",
    "    \n",
    "    grad[range(m),y.long()] -= 1\n",
    "    grad = grad/m\n",
    "    return grad\n",
    "\n",
    "def predict(x, w1, w2, act):\n",
    "    h = x.mm(w1)\n",
    "    if act is 'ReLU':\n",
    "        h_act = h.clamp(min=0)\n",
    "    elif act is 'Sig':\n",
    "        h_act = h * (1-h)\n",
    "    y_pred = h_act.mm(w2)\n",
    "    y_pred = softmax(y_pred)\n",
    "    return torch.max(y_pred, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step [1000/50000], Loss: 8.477\n",
      "Step [2000/50000], Loss: 8.458\n",
      "Step [3000/50000], Loss: 8.439\n",
      "Step [4000/50000], Loss: 8.42\n",
      "Step [5000/50000], Loss: 8.402\n",
      "Step [6000/50000], Loss: 8.383\n",
      "Step [7000/50000], Loss: 8.365\n",
      "Step [8000/50000], Loss: 8.348\n",
      "Step [9000/50000], Loss: 8.33\n",
      "Step [10000/50000], Loss: 8.313\n",
      "Step [11000/50000], Loss: 8.296\n",
      "Step [12000/50000], Loss: 8.28\n",
      "Step [13000/50000], Loss: 8.263\n",
      "Step [14000/50000], Loss: 8.247\n",
      "Step [15000/50000], Loss: 8.231\n",
      "Step [16000/50000], Loss: 8.215\n",
      "Step [17000/50000], Loss: 8.199\n",
      "Step [18000/50000], Loss: 8.184\n",
      "Step [19000/50000], Loss: 8.169\n",
      "Step [20000/50000], Loss: 8.154\n",
      "Step [21000/50000], Loss: 8.139\n",
      "Step [22000/50000], Loss: 8.124\n",
      "Step [23000/50000], Loss: 8.11\n",
      "Step [24000/50000], Loss: 8.096\n",
      "Step [25000/50000], Loss: 8.082\n",
      "Step [26000/50000], Loss: 8.068\n",
      "Step [27000/50000], Loss: 8.054\n",
      "Step [28000/50000], Loss: 8.04\n",
      "Step [29000/50000], Loss: 8.027\n",
      "Step [30000/50000], Loss: 8.014\n",
      "Step [31000/50000], Loss: 8.001\n",
      "Step [32000/50000], Loss: 7.988\n",
      "Step [33000/50000], Loss: 7.976\n",
      "Step [34000/50000], Loss: 7.963\n",
      "Step [35000/50000], Loss: 7.951\n",
      "Step [36000/50000], Loss: 7.94\n",
      "Step [37000/50000], Loss: 7.928\n",
      "Step [38000/50000], Loss: 7.917\n",
      "Step [39000/50000], Loss: 7.906\n",
      "Step [40000/50000], Loss: 7.895\n",
      "Step [41000/50000], Loss: 7.885\n",
      "Step [42000/50000], Loss: 7.874\n",
      "Step [43000/50000], Loss: 7.864\n",
      "Step [44000/50000], Loss: 7.853\n",
      "Step [45000/50000], Loss: 7.843\n",
      "Step [46000/50000], Loss: 7.833\n",
      "Step [47000/50000], Loss: 7.823\n",
      "Step [48000/50000], Loss: 7.814\n",
      "Step [49000/50000], Loss: 7.804\n",
      "Step [50000/50000], Loss: 7.795\n"
     ]
    }
   ],
   "source": [
    "# N is batch size; D_in is input dimension;\n",
    "# H is hidden dimension; D_out is output dimension.\n",
    "N, D_in, H, D_out = 112, 4, 7, 3\n",
    "\n",
    "#\n",
    "x = torch.as_tensor(torch.from_numpy(feature_train), device=device, dtype=dtype)\n",
    "y = torch.as_tensor(torch.from_numpy(labels_train), device=device, dtype=dtype)\n",
    "\n",
    "# Randomly initialize weights\n",
    "w1 = torch.randn(D_in, H, device=device, dtype=dtype)\n",
    "w2 = torch.randn(H, D_out, device=device, dtype=dtype)\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "learning_rate = 1e-6\n",
    "\n",
    "num_steps = 50000\n",
    "\n",
    "# MSE or CE\n",
    "loss_fn = 'CE'\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# ReLU or Sig\n",
    "activ_fn = 'ReLU'\n",
    "\n",
    "debug = {}\n",
    "\n",
    "for t in range(num_steps):\n",
    "    # Forward pass: compute predicted y\n",
    "    h = x.mm(w1)\n",
    "\n",
    "    if activ_fn is 'ReLU':\n",
    "        h_activation = h.clamp(min=0)\n",
    "    elif activ_fn is 'Sig':\n",
    "        h_activation = mc.sigmoid_activation(h)\n",
    "\n",
    "    y_pred = h_activation.mm(w2)\n",
    "\n",
    "    debug['y_pred'] = y_pred\n",
    "    debug['y'] = y\n",
    "    \n",
    "    # Compute and print loss\n",
    "    if loss_fn is 'MSE':\n",
    "        loss = mc.mean_sum_square_errors(y_pred, y)\n",
    "    elif loss_fn is 'CE':\n",
    "        #print(y_pred.shape, y.shape)\n",
    "        #print(y_pred, y)\n",
    "        loss = cross_ent(y_pred, y)\n",
    "        #loss = criterion(torch.argmax(y_pred), y.long())\n",
    "\n",
    "    loss_list.append(loss)\n",
    "\n",
    "    # Backprop to compute gradients of w1 and w2 with respect to loss\n",
    "    if loss_fn is 'MSE':\n",
    "        grad_y_pred = mc.sum_square_errors_delta(y_pred, y)\n",
    "    elif loss_fn is 'CE':\n",
    "        grad_y_pred = delta_cross_ent(y_pred, y)\n",
    "\n",
    "    #print('grad_y_pred', grad_y_pred.shape)\n",
    "    grad_w2 = h_activation.t().mm(grad_y_pred)\n",
    "    #print('grad_w2', grad_w2.shape)\n",
    "    grad_h_activation = grad_y_pred.mm(w2.t())\n",
    "    #print('grad_h_activation', grad_h_activation.shape)\n",
    "    grad_h = grad_h_activation.clone()\n",
    "\n",
    "    if activ_fn is 'ReLU':\n",
    "        grad_h[h < 0] = 0\n",
    "    elif activ_fn is 'Sig':\n",
    "        grad_h = grad_h * (1 - grad_h)\n",
    "\n",
    "    #print('grad_h', grad_h.shape)\n",
    "    \n",
    "    grad_w1 = x.t().mm(grad_h)\n",
    "\n",
    "    #print('grad_w1', grad_w1.shape)\n",
    "    \n",
    "    #print('w1', w1.shape)\n",
    "    #print('w2', w2.shape)\n",
    "    #print()\n",
    "    # Update weights using gradient descent\n",
    "    w1 -= learning_rate * grad_w1\n",
    "    w2 -= learning_rate * grad_w2\n",
    "\n",
    "    if (t + 1) % 10000 == 0:\n",
    "        print(f'Step [{t+1}/{num_steps}], Loss: {loss:.4}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "grad_y_pred torch.Size([112, 3])\n",
    "grad_w2 torch.Size([7, 3])\n",
    "grad_h_activation torch.Size([112, 7])\n",
    "grad_h torch.Size([112, 7])\n",
    "grad_w1 torch.Size([4, 7])\n",
    "w1 torch.Size([4, 7])\n",
    "w2 torch.Size([7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "grad_y_pred torch.Size([112, 3])\n",
    "grad_w2 torch.Size([7, 3])\n",
    "grad_h_activation torch.Size([112, 7])\n",
    "grad_h torch.Size([112, 7])\n",
    "grad_w1 torch.Size([4, 7])\n",
    "w1 torch.Size([4, 7])\n",
    "w2 torch.Size([7, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([112, 3])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad = debug['grad']\n",
    "\n",
    "grad[range(3), y.long()].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc: 0.13\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "x_test = torch.from_numpy(feature_test).float()\n",
    "y_test = torch.from_numpy(labels_test).float()\n",
    "\n",
    "y_preds = predict(x_test, w1, w2, activ_fn)[1]\n",
    "\n",
    "# Compute accuracy\n",
    "_, argmax = torch.max(y_test, 1)\n",
    "accuracy = (y_preds == argmax.squeeze()).float().mean()\n",
    "\n",
    "print(f'Acc: {accuracy:.2}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_pred\n",
      "torch.Size([112, 3])\n",
      "y\n",
      "torch.Size([112, 3])\n"
     ]
    }
   ],
   "source": [
    "for k, v in debug.items():\n",
    "    print(k)\n",
    "    print(v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cross_ent(y_hat, y):\n",
    "    y_soft = softmax(y_hat)\n",
    "    #print(y.shape)\n",
    "    return torch.mean( torch.sum(- y.float() * torch.log(y_soft), 1))\n",
    "\n",
    "# SOFTMAX\n",
    "def softmax(X):\n",
    "    exps = torch.exp(X - torch.max(X))\n",
    "    return exps / exps.sum()\n",
    "\n",
    "def delta_cross_ent(X, y):\n",
    "    '''\n",
    "    X: output of last fully connected layer, dim = [num_examples, num_classes]\n",
    "    y: labels (not one-hot encoded), dim = [num_examples, 1]\n",
    "    output: gradient of cross entropy function wrt output, dim = [num_examples, num_classes]\n",
    "    '''\n",
    "    m = y.shape[0]\n",
    "    labels = y.argmax(1)\n",
    "    #print(y.shape)\n",
    "    grad = softmax(X)\n",
    "    grad[range(m),labels] -= 1\n",
    "    grad = grad/m\n",
    "    return grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 0, 1],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [1, 0, 0],\n",
       "        [1, 0, 0],\n",
       "        [0, 1, 0],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1],\n",
       "        [0, 0, 1]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.byte()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(9.7122)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_ent(debug['y_pred'], debug['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([112])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(9.7122)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = debug['y_pred']\n",
    "\n",
    "labels = y.argmax(1)\n",
    "print(labels.shape)\n",
    "y_soft = softmax(y_hat)\n",
    "torch.mean( torch.sum(- y * torch.log(y_soft), 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 0, 1, 1, 0, 1, 2, 1, 1, 2, 1, 0, 2, 1, 1, 1, 1, 0, 1, 2, 2, 0, 0, 2,\n",
       "        0, 2, 2, 0, 2, 0, 0, 1, 2, 0, 0, 1, 0, 2, 2, 0, 0, 1, 2, 2, 0, 0, 2, 0,\n",
       "        0, 2, 2, 2, 2, 0, 2, 1, 0, 1, 0, 0, 1, 1, 1, 2, 1, 2, 2, 1, 1, 2, 2, 1,\n",
       "        0, 2, 2, 1, 2, 1, 0, 1, 0, 1, 1, 2, 0, 1, 0, 2, 1, 0, 0, 1, 0, 2, 0, 2,\n",
       "        0, 1, 2, 0, 0, 0, 2, 0, 0, 1, 0, 0, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.5195e-06, -8.9279e-03,  5.3537e-07],\n",
       "        [-8.9242e-03,  8.5554e-08,  2.4602e-05],\n",
       "        [ 1.1009e-06, -8.9279e-03,  1.1824e-06],\n",
       "        [ 7.1905e-06, -8.9273e-03,  7.6243e-08],\n",
       "        [-8.9268e-03,  4.1026e-10,  2.2414e-05],\n",
       "        [ 1.1489e-06, -8.9275e-03,  8.0467e-07],\n",
       "        [ 2.8277e-05,  3.7228e-06, -8.9285e-03],\n",
       "        [ 1.6129e-06, -8.9272e-03,  5.9732e-07],\n",
       "        [ 1.5055e-06, -8.9285e-03,  1.7925e-06],\n",
       "        [ 2.5622e-06,  1.7824e-06, -8.9282e-03],\n",
       "        [ 1.9689e-05, -8.9266e-03,  3.4864e-08],\n",
       "        [-8.9263e-03,  1.3587e-08,  5.5463e-05],\n",
       "        [ 3.8374e-06,  9.4689e-09, -8.9280e-03],\n",
       "        [ 4.1309e-06, -8.9272e-03,  1.1331e-07],\n",
       "        [ 1.2248e-06, -8.9275e-03,  7.6069e-07],\n",
       "        [ 1.3436e-05, -8.9262e-03,  4.7847e-08],\n",
       "        [ 1.5011e-06, -8.9273e-03,  6.3622e-07],\n",
       "        [-8.9228e-03,  3.1889e-09,  7.7023e-04],\n",
       "        [ 3.5268e-05, -8.9263e-03,  1.6989e-08],\n",
       "        [ 2.5622e-06,  1.7824e-06, -8.9282e-03],\n",
       "        [ 6.4734e-06,  2.7829e-06, -8.9285e-03],\n",
       "        [-8.9264e-03,  9.3912e-10,  1.3481e-04],\n",
       "        [-8.9271e-03,  2.5906e-10,  1.4506e-04],\n",
       "        [ 3.8383e-05,  4.2838e-06, -8.9286e-03],\n",
       "        [-8.9250e-03,  1.1941e-07,  1.5897e-05],\n",
       "        [ 2.3403e-06,  1.6829e-06, -8.9281e-03],\n",
       "        [ 4.5612e-06,  1.2373e-06, -8.9284e-03],\n",
       "        [-8.9238e-03,  9.2304e-10,  8.2191e-07],\n",
       "        [ 3.1216e-06,  1.2768e-06, -8.9285e-03],\n",
       "        [-8.9277e-03,  1.3231e-09,  2.0354e-04],\n",
       "        [-8.9162e-03,  2.0606e-10,  3.0108e-07],\n",
       "        [ 1.8982e-06, -8.9279e-03,  4.1849e-07],\n",
       "        [ 3.7996e-05,  7.4017e-08, -8.9286e-03],\n",
       "        [-8.9262e-03,  3.6322e-10,  2.9875e-04],\n",
       "        [-8.9273e-03,  3.0463e-11,  1.1518e-04],\n",
       "        [ 1.7685e-05, -8.9271e-03,  3.5576e-08],\n",
       "        [-8.9237e-03,  6.9615e-08,  3.7658e-05],\n",
       "        [ 9.7946e-06,  2.8706e-06, -8.9285e-03],\n",
       "        [ 6.7597e-05,  5.0571e-06, -8.9286e-03],\n",
       "        [-8.9238e-03,  8.5912e-09,  2.3925e-04],\n",
       "        [-8.9243e-03,  5.4506e-12,  7.8724e-06],\n",
       "        [ 3.8239e-06, -8.9282e-03,  4.7544e-06],\n",
       "        [ 1.8564e-05,  1.5666e-06, -8.9285e-03],\n",
       "        [ 2.8862e-04,  8.7381e-06, -8.9286e-03],\n",
       "        [-8.9208e-03,  2.7860e-08,  1.2815e-04],\n",
       "        [-8.9258e-03,  1.8072e-07,  8.5021e-06],\n",
       "        [ 4.5367e-06,  1.4386e-08, -8.9283e-03],\n",
       "        [-8.9246e-03,  1.0097e-07,  2.0052e-05],\n",
       "        [-8.9268e-03,  5.6482e-11,  1.9753e-04],\n",
       "        [ 7.0346e-05,  2.0319e-06, -8.9286e-03],\n",
       "        [ 8.0528e-06,  4.0350e-07, -8.9286e-03],\n",
       "        [ 3.0704e-05,  1.0213e-06, -8.9286e-03],\n",
       "        [ 5.1822e-06,  3.9745e-07, -8.9285e-03],\n",
       "        [-8.9238e-03,  7.7319e-08,  2.5772e-05],\n",
       "        [ 6.4098e-06,  6.8455e-07, -8.9268e-03],\n",
       "        [ 1.5013e-06, -8.9274e-03,  7.3557e-07],\n",
       "        [-8.9249e-03,  1.0138e-08,  2.4360e-06],\n",
       "        [ 1.6161e-06, -8.9272e-03,  5.9626e-07],\n",
       "        [-8.9193e-03,  1.0465e-12,  2.9978e-06],\n",
       "        [-8.9269e-03,  2.4539e-08,  4.7722e-06],\n",
       "        [ 6.0079e-06, -8.9274e-03,  6.8725e-08],\n",
       "        [ 1.6727e-06, -8.9280e-03,  2.0076e-06],\n",
       "        [ 2.3788e-06, -8.9277e-03,  3.5933e-07],\n",
       "        [ 3.2087e-06,  3.5653e-06, -8.9283e-03],\n",
       "        [ 1.4886e-06, -8.9282e-03,  2.6954e-06],\n",
       "        [ 5.1373e-05,  6.0773e-06, -8.9286e-03],\n",
       "        [ 3.5818e-06,  3.2532e-06, -8.9283e-03],\n",
       "        [ 2.6875e-06, -8.9276e-03,  2.1586e-07],\n",
       "        [ 1.0856e-06, -8.9276e-03,  8.3230e-07],\n",
       "        [ 2.9040e-06,  1.1838e-06, -8.9283e-03],\n",
       "        [ 2.3746e-06,  1.0923e-06, -8.9282e-03],\n",
       "        [ 1.6973e-06, -8.9266e-03,  4.8072e-07],\n",
       "        [-8.9267e-03,  2.6145e-09,  1.1461e-04],\n",
       "        [ 4.6382e-05,  6.4470e-06, -8.9286e-03],\n",
       "        [ 4.9579e-04,  4.7521e-06, -8.9286e-03],\n",
       "        [ 2.6368e-06, -8.9280e-03,  2.8074e-07],\n",
       "        [ 1.0245e-04,  7.1658e-06, -8.9286e-03],\n",
       "        [ 4.9410e-06, -8.9279e-03,  8.2335e-08],\n",
       "        [-8.9206e-03,  2.9313e-08,  1.5242e-04],\n",
       "        [ 1.7495e-06, -8.9272e-03,  5.5613e-07],\n",
       "        [-8.9264e-03,  2.0608e-08,  4.4205e-05],\n",
       "        [ 6.2628e-05, -8.9270e-03,  7.6439e-09],\n",
       "        [ 2.0148e-06, -8.9270e-03,  4.9125e-07],\n",
       "        [ 9.8841e-06,  2.3570e-07, -8.9199e-03],\n",
       "        [-8.9270e-03,  2.8298e-09,  2.8666e-05],\n",
       "        [ 2.2005e-06, -8.9283e-03,  9.1574e-08],\n",
       "        [-8.9166e-03,  1.5728e-08,  3.4813e-04],\n",
       "        [ 5.1918e-06,  5.7678e-07, -8.9264e-03],\n",
       "        [ 3.3183e-06, -8.9276e-03,  1.8038e-07],\n",
       "        [-8.9274e-03,  1.5696e-11,  1.8617e-04],\n",
       "        [-8.9235e-03,  1.5645e-08,  1.3852e-04],\n",
       "        [ 1.4166e-06, -8.9275e-03,  8.2206e-07],\n",
       "        [-8.9268e-03,  2.8626e-12,  5.7906e-05],\n",
       "        [ 4.4079e-05,  2.2702e-06, -8.9286e-03],\n",
       "        [-8.9233e-03,  6.1920e-08,  4.0888e-05],\n",
       "        [ 1.6600e-06,  9.1160e-07, -8.9280e-03],\n",
       "        [-8.9268e-03,  5.3524e-10,  1.0233e-03],\n",
       "        [ 1.5644e-06, -8.9271e-03,  5.7377e-07],\n",
       "        [ 3.1080e-04,  5.3977e-08, -8.9286e-03],\n",
       "        [-8.9263e-03,  7.3891e-10,  9.1428e-06],\n",
       "        [-8.9267e-03,  3.0021e-07,  5.4763e-06],\n",
       "        [-8.9266e-03,  1.4382e-09,  7.1777e-05],\n",
       "        [ 5.0931e-05,  4.5660e-06, -8.9286e-03],\n",
       "        [-8.9270e-03,  4.6106e-09,  6.5944e-05],\n",
       "        [-8.9269e-03,  7.5424e-09,  3.5901e-05],\n",
       "        [ 2.8494e-06, -8.9278e-03,  2.8620e-07],\n",
       "        [-8.9255e-03,  1.5377e-08,  8.1135e-06],\n",
       "        [-8.9265e-03,  4.7102e-11,  1.8052e-03],\n",
       "        [ 2.2759e-06, -8.9280e-03,  2.2236e-06],\n",
       "        [ 2.0820e-06,  1.5626e-06, -8.9281e-03],\n",
       "        [ 1.5868e-05,  9.1110e-07, -8.9286e-03],\n",
       "        [ 2.9797e-06,  1.5702e-06, -8.9283e-03]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta_cross_ent(y_pred, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "soft = softmax(y_hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "112"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
